{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Districts: 100%|██████████| 53/53 [02:36<00:00,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping complete. Data saved to centanet_ici_buildings.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# File paths\n",
    "excel_file = \"Centanet_ICI_Area_Code.xlsx\"  # Excel file with district info (see [1])\n",
    "csv_filename = \"centanet_ici_buildings.csv\"\n",
    "\n",
    "# Read districts from the Excel file (Sheet1 with columns: Region, District, Code)\n",
    "df = pd.read_excel(excel_file, sheet_name=\"Sheet1\")\n",
    "\n",
    "# Define CSV fields – adding the queried district info for reference\n",
    "fields = [\n",
    "    \"queriedDistrict\", \"queriedCode\", \"propertyID\", \"buildingNameEn\", \n",
    "    \"address\", \"developers\", \"opDateDisplayName\", \"floorDisplayName\", \n",
    "    \"districtNameEn\", \"zoneEn\", \"sellCount\", \"rentCount\", \"transCount\"\n",
    "]\n",
    "\n",
    "# If the CSV does not already exist, create it and write the header\n",
    "if not os.path.exists(csv_filename):\n",
    "    with open(csv_filename, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fields)\n",
    "        writer.writeheader()\n",
    "\n",
    "# Base API URL\n",
    "base_url = \"https://oir.centanet.com/api/Property/GetPropertyList\"\n",
    "\n",
    "# Set headers and cookies (anti-scraping measures)\n",
    "headers = {\n",
    "    \"sec-ch-ua\": '\"Not(A:Brand\";v=\"99\", \"Google Chrome\";v=\"133\", \"Chromium\";v=\"133\"',\n",
    "    \"sec-ch-ua-mobile\": \"?0\",\n",
    "    \"sec-ch-ua-platform\": '\"macOS\"',\n",
    "    \"sec-fetch-dest\": \"empty\",\n",
    "    \"sec-fetch-mode\": \"cors\",\n",
    "    \"sec-fetch-site\": \"same-origin\",\n",
    "    \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36\",\n",
    "    \"referer\": \"https://oir.centanet.com/en/property/search/?pageindex=2&depts=Any&districtids=WS012\",\n",
    "}\n",
    "\n",
    "cookies = {\n",
    "    \"gr_user_id\": \"24005ea2-e47e-4e55-baed-171d8f324a03\",\n",
    "    # Add additional cookies if needed\n",
    "}\n",
    "\n",
    "# Iterate over each district in the Excel file using tqdm\n",
    "for _, district_row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Districts\"):\n",
    "    queried_district = district_row[\"District\"]\n",
    "    queried_code = district_row[\"Code\"]\n",
    "    page_index = 1\n",
    "\n",
    "    while True:\n",
    "        # Build the query parameters for each page\n",
    "        params = {\n",
    "            \"PageSize\": 24,\n",
    "            \"pageindex\": page_index,\n",
    "            \"depts\": \"Any\",\n",
    "            \"districtids\": queried_code,\n",
    "            \"lang\": \"EN\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(base_url, headers=headers, cookies=cookies, params=params)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {queried_district} (code: {queried_code}) page {page_index}: {e}\")\n",
    "            break\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Non-200 status for {queried_district} (code: {queried_code}) page {page_index}: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            result_json = response.json()\n",
    "        except Exception as e:\n",
    "            print(f\"JSON parsing error for {queried_district} (code: {queried_code}) page {page_index}: {e}\")\n",
    "            break\n",
    "\n",
    "        # Check for items; if empty then we assume the last page has been reached\n",
    "        items = result_json.get(\"data\", {}).get(\"items\", [])\n",
    "        if not items:\n",
    "            break\n",
    "\n",
    "        # Open CSV in append mode so results are written immediately (protecting against data loss)\n",
    "        with open(csv_filename, mode='a', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fields)\n",
    "            for item in items:\n",
    "                # Assemble row data; developers is converted from a list to a comma-separated string\n",
    "                row_data = {\n",
    "                    \"queriedDistrict\": queried_district,\n",
    "                    \"queriedCode\": queried_code,\n",
    "                    \"propertyID\": item.get(\"propertyID\"),\n",
    "                    \"buildingNameEn\": item.get(\"buildingNameEn\"),\n",
    "                    \"address\": item.get(\"address\"),\n",
    "                    \"developers\": \", \".join(item.get(\"developers\", [])),\n",
    "                    \"opDateDisplayName\": item.get(\"opDateDisplayName\"),\n",
    "                    \"floorDisplayName\": item.get(\"floorDisplayName\"),\n",
    "                    \"districtNameEn\": item.get(\"areaInfo\", {}).get(\"districtNameEn\"),\n",
    "                    \"zoneEn\": item.get(\"areaInfo\", {}).get(\"zoneEn\"),\n",
    "                    \"sellCount\": item.get(\"sellCount\"),\n",
    "                    \"rentCount\": item.get(\"rentCount\"),\n",
    "                    \"transCount\": item.get(\"transCount\")\n",
    "                }\n",
    "                writer.writerow(row_data)\n",
    "        \n",
    "        #print(f\"Processed {queried_district} (code: {queried_code}) page {page_index} with {len(items)} item(s)\")\n",
    "        page_index += 1\n",
    "        time.sleep(1)  # Pause between requests as an anti-scraping measure\n",
    "\n",
    "print(\"Scraping complete. Data saved to\", csv_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
