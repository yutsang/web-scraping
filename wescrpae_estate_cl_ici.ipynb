{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Constants\n",
    "CSV_HEADERS = [\n",
    "    'property_name', 'property_type', 'address', 'area', 'year',\n",
    "    'floors', 'developer', 'transaction_count', 'image_url',\n",
    "    'region', 'district', 'code'\n",
    "]\n",
    "\n",
    "# Set up logging\n",
    "def setup_logging(log_dir=\"logs\"):\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(f\"{log_dir}/scraper_{timestamp}.log\"),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "def init_csv():\n",
    "    csv_filename = f\"{datetime.now().strftime('%Y%m%d')}_centanet_estates_ici.csv\"\n",
    "    if not os.path.exists(csv_filename):\n",
    "        with open(csv_filename, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=CSV_HEADERS)\n",
    "            writer.writeheader()\n",
    "    return csv_filename\n",
    "\n",
    "def safe_extract(card, selector, attr=None):\n",
    "    try:\n",
    "        elem = card.select_one(selector)\n",
    "        if not elem:\n",
    "            return ''\n",
    "        if attr:\n",
    "            return elem.get(attr, '').strip()\n",
    "        return elem.text.strip()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Extraction error: {e}\")\n",
    "        return ''\n",
    "\n",
    "def extract_property_data(card):\n",
    "    return {\n",
    "        'property_name': safe_extract(card, 'h3.col-top-title'),\n",
    "        'property_type': safe_extract(card, 'div.col-center p').split('|')[0].strip() if '|' in safe_extract(card, 'div.col-center p') else '',\n",
    "        'address': safe_extract(card, 'div.col-center p').split('|')[-1].strip(),\n",
    "        'area': safe_extract(card, 'p.area'),\n",
    "        'year': safe_extract(card, 'p.opDate'),\n",
    "        'floors': safe_extract(card, 'p.floor'),\n",
    "        'developer': safe_extract(card, 'p.developer'),\n",
    "        'transaction_count': safe_extract(card, 'div.col-top-butn p span'),\n",
    "        'image_url': safe_extract(card, 'div.img-size img', 'src')\n",
    "    }\n",
    "\n",
    "def scrape_page(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36',\n",
    "        'Referer': urlparse(url).scheme + '://' + urlparse(url).netloc + '/'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        return [extract_property_data(card) for card in soup.select('div.property-database-results-card')], True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Page scrape failed: {e}\")\n",
    "        return [], False\n",
    "\n",
    "def scrape_area(region, district, code, csv_filename, max_pages=100):\n",
    "    page_index = 1\n",
    "    district_url = district.lower().replace(' ', '-')\n",
    "    base_url = f\"https://oir.centanet.com/en/property/all-usage/{region.lower()}-{district_url}/{code.lower()}\"\n",
    "    \n",
    "    while page_index <= max_pages:\n",
    "        page_url = f\"{base_url}/?pageindex={page_index}\"\n",
    "        properties, success = scrape_page(page_url)\n",
    "        \n",
    "        if not success or not properties:\n",
    "            break\n",
    "            \n",
    "        with open(csv_filename, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=CSV_HEADERS)\n",
    "            for prop in properties:\n",
    "                prop.update({\n",
    "                    'region': region,\n",
    "                    'district': district,\n",
    "                    'code': code\n",
    "                })\n",
    "                writer.writerow(prop)\n",
    "        \n",
    "        logger.info(f\"Page {page_index} saved: {len(properties)} records\")\n",
    "        page_index += 1\n",
    "        time.sleep(1.2)\n",
    "    \n",
    "    return page_index - 1  # Return number of pages scraped\n",
    "\n",
    "def main():\n",
    "    global logger\n",
    "    logger = setup_logging()\n",
    "    csv_filename = init_csv()\n",
    "    \n",
    "    try:\n",
    "        area_codes = pd.read_excel(\"Centanet_ICI_Area_Code.xlsx\").to_dict('records')\n",
    "        logger.info(f\"Loaded {len(area_codes)} area codes\")\n",
    "        \n",
    "        for area in area_codes:\n",
    "            logger.info(f\"Scraping {area['Region']} - {area['District']}\")\n",
    "            pages_scraped = scrape_area(\n",
    "                area['Region'],\n",
    "                area['District'],\n",
    "                area['Code'],\n",
    "                csv_filename\n",
    "            )\n",
    "            logger.info(f\"Completed {pages_scraped} pages for {area['District']}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Main execution failed: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
